{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import vgg19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    data_path: str = \"\"\n",
    "    batch_size: int = 32\n",
    "    pin_memory: bool = True\n",
    "    num_workers: int = 2\n",
    "    lr: float = 0.0005\n",
    "    momentum: float = 0.9\n",
    "    betas: tuple = (.9, .999)\n",
    "    seed: int = 42\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "def set_seed(seed=Config.seed):\n",
    "    if Config.seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.random.manual_seed(seed)\n",
    "        print(f\"Manual Seed set to {seed}\")\n",
    "    else:\n",
    "        print(\"seed was nulltype so no seed set\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRGAN Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    # conv -> BN -> pReLU | LeakyReLU\n",
    "    def __init__(self, in_channels, out_channels, \n",
    "                 discriminator: bool = False, \n",
    "                 use_act=True, use_bn=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv2d(in_channels, out_channels, \n",
    "                             **kwargs, bias=(not use_bn))   \n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
    "        self.act = (nn.LeakyReLU(0.2, inplace=True) \n",
    "                    if discriminator \n",
    "                    else nn.PReLU(out_channels)\n",
    "                    )\n",
    "        \n",
    "        self.use_act = use_act\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.cnn(x))) if self.use_act else self.bn(self.cnn(x))\n",
    "    \n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, sf):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels*sf**2, 3, 1, 1)\n",
    "        self.ps = nn.PixelShuffle(sf)  # in_ch *4, H, W -> in_ch, H*2, W*2\n",
    "        self.act = nn.PReLU(in_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.act(self.ps(self.conv(x)))\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.block1 = ConvBlock(in_channels, in_channels, \n",
    "                                kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.block2 = ConvBlock(in_channels, in_channels, \n",
    "                                kernel_size=3, stride=1, padding=1, \n",
    "                                use_act=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        return out + x\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_channels=64, num_blocks=16):\n",
    "        super().__init__()\n",
    "        self.initial = ConvBlock(in_channels, num_channels, \n",
    "                                 kernel_size=9, stride=1, \n",
    "                                 padding=4, use_bn=False)\n",
    "        \n",
    "        self.resnet = nn.Sequential(*[ResidualBlock(num_channels) for _ in range(num_blocks)])\n",
    "        self.conv = ConvBlock(num_channels, num_channels, \n",
    "                              kernel_size=3, stride=1, \n",
    "                              padding=1, use_act=False)\n",
    "        self.upsnet = nn.Sequential(UpsampleBlock(num_channels, sf=2),\n",
    "                                    UpsampleBlock(num_channels, sf=2))\n",
    "        self.final = nn.Conv2d(num_channels, in_channels, kernel_size=9, \n",
    "                               stride=1, padding=4)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        init = self.initial(image)\n",
    "        image = self.resnet(init)\n",
    "        image = self.conv(image) + init\n",
    "        image = self.upsnet(image)\n",
    "        \n",
    "        return torch.tanh(self.final(image))\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, \n",
    "                 features=[64, 64, 128, 128, 256, 256, 512, 512]):\n",
    "        super().__init__()\n",
    "        \n",
    "        blocks = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            blocks.append(\n",
    "                ConvBlock(in_channels, feature, discriminator=True,\n",
    "                          kernel_size=3, stride=1+idx%2,\n",
    "                          use_act=True,\n",
    "                          use_bn=False if idx == 0 else True\n",
    "                         )\n",
    "            )\n",
    "            in_channels=feature\n",
    "            \n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((6, 6)),  # ensures running for variable i/p size\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*6*6, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 1),\n",
    "            # nn.Sigmoid()  ## optional\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return self.classifier(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    low_res=128\n",
    "    with torch.cuda.amp.autocast():\n",
    "        x = torch.randn((5, 3, low_res, low_res))\n",
    "        gen = Generator()\n",
    "        gen_out = gen(x)\n",
    "        disc = Discriminator()\n",
    "        disc_out = disc(gen_out)\n",
    "        \n",
    "        print(gen_out.shape)\n",
    "        print(disc_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 512, 512])\n",
      "torch.Size([5, 1])\n",
      "time taken: 5.8180s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "test()\n",
    "print(f\"time taken: {time.perf_counter() - start:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi_5,4 5th conv layer before maxpooling but after activation\n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vgg = vgg19(pretrained=True).features[:36].eval().to(config.device)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        vgg_input_features = self.vgg(input)\n",
    "        vgg_target_features = self.vgg(target)\n",
    "        return self.loss(vgg_input_features, vgg_target_features)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acdc42e64075ed84238d7fd09f2d8bcb4020cca83228aadc2e65557d070735c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
